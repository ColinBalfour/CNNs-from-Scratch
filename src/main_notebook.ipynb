{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "593eb79b",
            "metadata": {},
            "source": [
                "# P1: Nifty Neural Networks!\n",
                "\n",
                "\n",
                "## Table Of Content\n",
                "\n",
                "1. Introduction\n",
                "2. Preliminaries\n",
                "3. Software Setup\n",
                "4. Implementation\n",
                "5. Grading Rubric\n",
                "6. Report guidelines\n",
                "\n",
                "## 1. Introduction\n",
                "\n",
                "Neural networks, at their core, function like any other mathematical function that can be evaluated. The process of evaluating a neural network is referred to as the forward pass. During this step, inputs are passed through the network layers, and outputs are generated.\n",
                "\n",
                "To optimize the network's performance, its weights and biases need to be adjusted. This is done through a process called backward propagation (or backpropagation). In this step, the gradients of the loss function with respect to each parameter are calculated, and these gradients are subtracted from the corresponding weights and biases, allowing the network to learn and improve its predictions.\n",
                "\n",
                "In this assignment, you will dive into the implementation of custom layers in PyTorch. Specifically, you will focus on coding the forward pass and computing the gradients necessary for the backward pass. Before you begin, make sure to review the grading rubric to understand the criteria for evaluation.\n",
                "\n",
                "## 2. Preliminaries\n",
                "\n",
                "### CIFAR10 Dataset\n",
                "\n",
                "CIFAR-10 is a dataset consisting of 60000, 32Ã—32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. More details about the datset can be found [here](http://www.cs.toronto.edu/~kriz/cifar.html).\n",
                "\n",
                "Sample images from each class of the CIFAR-10 dataset is shown below:\n",
                "\n",
                "![CIFAR 10](./artifacts/cifar10.png)\n",
                "\n",
                "In this project, you will classify images into these 10 classes using the provided pipeline,loaders and helper classes.\n",
                "\n",
                "Additionally, you are expected to generate a confusion matrix to evaluate your model's performance. For guidance on plotting a confusion matrix in PyTorch, please refer to this [resource](https://stackoverflow.com/questions/74020233/how-to-plot-confusion-matrix-in-pytorch).\n",
                "\n",
                "### Linear Layer\n",
                "A linear layer in a neural network performs a linear transformation of the input data. It is defined by the following components:\n",
                "\n",
                "1. Weights\n",
                "2. Biases\n",
                "\n",
                "More details below,\n",
                "\n",
                "[Pytorch Linear Layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
                "\n",
                "You can find information about the dimension of weights and biases in custom_layers.py\n",
                "\n",
                "### Soft Max\n",
                "The Softmax function is commonly used in neural networks for multi-class classification problems. It converts a vector of raw scores (logits) into probabilities, making it possible to interpret the output as the likelihood of each class.\n",
                "\n",
                "[Sample implementation](https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python)\n",
                "\n",
                "More details [here](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html).\n",
                "\n",
                "### Convolutional Layer\n",
                "\n",
                "A convolutional layer is a fundamental building block in Convolutional Neural Networks (CNNs) used primarily for processing grid-like data such as images. It applies convolution operations to detect local features in the input.\n",
                "\n",
                "Although it is called a convolutional layer, the PyTorch implementation of conv2d does not actually perform a convolution in the mathematical sense. Instead, it performs a cross-correlation operation, where the kernel is not flipped. This distinction is important to note, but for most deep learning projects including this one, cross-correlation is perfectly fine as the weights will automatically adjust during training.\n",
                "\n",
                "For more details, refer to [P0](https://rbe549.github.io/rbe474x/fall2024a/proj/p0/).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa4f305e",
            "metadata": {},
            "source": [
                "## 3. Software Setup\n",
                "\n",
                "Use a code editor like VSCode and open this entire folder.\n",
                "\n",
                "For each part, you will be implementing the corresponding layers in custom_layers.py\n",
                "\n",
                "The code will automatically be tested with test.py. \n",
                "\n",
                "To run the test, open a terminal in the current folder and run,\n",
                "\n",
                "`pytest -s -v test.py`"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5c586079",
            "metadata": {},
            "source": [
                "## 4. Implementation \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d925fff4",
            "metadata": {},
            "source": [
                "### Part1 : Implement Your Custom Layers for Multi Layer Perceptron (MLP)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0fcb96b9",
            "metadata": {},
            "source": [
                "Open custom_layers.py and implement a fully connected, relu and softmax layer.\n",
                "\n",
                "Verify it by running the below code. Feel free to modify the below snippet. But do not modify my test.py\n",
                "\n",
                "For more information about supplying gradients, please refer to [examples_autograd](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "2bc90238",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Linear\n",
                        "Inference for linear layer\n",
                        "tensor([[0.2076, 0.2621]], grad_fn=<CustomLinearLayerBackward>)\n",
                        "tensor([[0.2076, 0.2621]], grad_fn=<AddmmBackward0>)\n",
                        "\n",
                        "graidents for linear layer\n",
                        "tensor([[0.2006, 0.1601, 0.1958, 0.0077, 0.1246, 0.1974, 0.0907, 0.0015, 0.0865,\n",
                        "         0.0629],\n",
                        "        [0.2532, 0.2020, 0.2472, 0.0098, 0.1573, 0.2492, 0.1144, 0.0019, 0.1091,\n",
                        "         0.0794]])\n",
                        "tensor([[0.2006, 0.1601, 0.1958, 0.0077, 0.1246, 0.1974, 0.0907, 0.0015, 0.0865,\n",
                        "         0.0629],\n",
                        "        [0.2532, 0.2020, 0.2472, 0.0098, 0.1573, 0.2492, 0.1144, 0.0019, 0.1091,\n",
                        "         0.0794]])\n",
                        "tensor([0.2076, 0.2621])\n",
                        "tensor([0.2076, 0.2621])\n",
                        "\n",
                        "RELU\n",
                        "inference\n",
                        "tensor([[0.7957, 0.4725, 0.2756, 0.6456, 0.2341, 0.8199, 0.3778, 0.6002, 0.0037,\n",
                        "         0.3468]], grad_fn=<CustomReLULayerBackward>)\n",
                        "tensor([[0.7957, 0.4725, 0.2756, 0.6456, 0.2341, 0.8199, 0.3778, 0.6002, 0.0037,\n",
                        "         0.3468]], grad_fn=<ReluBackward0>)\n",
                        "gradients of loss relative to the input\n",
                        "tensor([[0.1591, 0.0945, 0.0551, 0.1291, 0.0468, 0.1640, 0.0756, 0.1200, 0.0007,\n",
                        "         0.0694]])\n",
                        "tensor([[0.1591, 0.0945, 0.0551, 0.1291, 0.0468, 0.1640, 0.0756, 0.1200, 0.0007,\n",
                        "         0.0694]])\n",
                        "\n",
                        " SoftMax\n",
                        "gradients of loss relative to the input\n",
                        "tensor([[-0.0220, -0.0229,  0.0449]])\n",
                        "tensor([[-0.0220, -0.0229,  0.0449]])\n"
                    ]
                }
            ],
            "source": [
                "import importlib\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "import networks as net\n",
                "importlib.reload(net)\n",
                "\n",
                "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
                "\n",
                "print(\"\\nLinear\")\n",
                "u = torch.rand((1, 10)).to(device)\n",
                "customLayer = net.CustomLinear(10, 2).to(device)\n",
                "inbuiltLayer = nn.Linear(in_features=10, out_features=2).to(device)\n",
                "\n",
                "inbuiltLayer.weight.data.copy_(customLayer.weight.data)\n",
                "inbuiltLayer.bias.data.copy_(customLayer.bias.data)\n",
                "\n",
                "y_custom = customLayer(u)\n",
                "y_inbuilt = inbuiltLayer(u)\n",
                "print(\"Inference for linear layer\")\n",
                "print(y_custom)\n",
                "print(y_inbuilt)\n",
                "\n",
                "lossFunc = nn.MSELoss()\n",
                "\n",
                "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
                "loss_in.backward()\n",
                "\n",
                "loss_custom = lossFunc(\n",
                "    y_custom,\n",
                "    torch.zeros_like(\n",
                "        y_custom,\n",
                "    ),\n",
                ")\n",
                "loss_custom.backward()\n",
                "\n",
                "\n",
                "print(\"\\ngraidents for linear layer\")\n",
                "print(customLayer.weight.grad)\n",
                "print(inbuiltLayer.weight.grad)\n",
                "\n",
                "print(customLayer.bias.grad)\n",
                "print(inbuiltLayer.bias.grad)\n",
                "\n",
                "# RELU\n",
                "print(\"\\nRELU\")\n",
                "u1 = torch.rand((1, 10), requires_grad=True)\n",
                "u2 = u1.detach().clone()\n",
                "u2.requires_grad_()\n",
                "\n",
                "customLayer = net.CustomReLU()\n",
                "inbuiltLayer = nn.ReLU()\n",
                "\n",
                "y_custom = customLayer(u1)\n",
                "y_inbuilt = inbuiltLayer(u2)\n",
                "\n",
                "loss_custom = lossFunc(y_custom, torch.zeros_like(y_custom))\n",
                "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
                "\n",
                "loss_custom.backward()\n",
                "loss_in.backward()\n",
                "\n",
                "print(\"inference\")\n",
                "print(y_custom)\n",
                "print(y_inbuilt)\n",
                "\n",
                "print(\"gradients of loss relative to the input\")\n",
                "print(u1.grad)\n",
                "print(u2.grad)\n",
                "\n",
                "# SOFTMAX\n",
                "print(\"\\n SoftMax\")\n",
                "\n",
                "u1 = torch.rand((1, 3), requires_grad=True)\n",
                "u2 = u1.detach().clone()\n",
                "u2.requires_grad_()\n",
                "customLayer = net.CustomSoftmax(1)\n",
                "inbuiltLayer = nn.Softmax()\n",
                "\n",
                "y_custom = customLayer(u1)\n",
                "y_inbuilt = inbuiltLayer(u2)\n",
                "\n",
                "loss_custom = lossFunc(y_custom, torch.zeros_like(y_custom))\n",
                "loss_in = lossFunc(y_inbuilt, torch.zeros_like(y_inbuilt))\n",
                "\n",
                "loss_custom.backward()\n",
                "loss_in.backward()\n",
                "\n",
                "print(\"gradients of loss relative to the input\")\n",
                "print(u1.grad)\n",
                "print(u2.grad)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8eb0ae69",
            "metadata": {},
            "source": [
                "### Part 2: MLP Network Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d10d7c7",
            "metadata": {},
            "source": [
                "Now that you have implemented an MLP from scratch, it's time to train it and verify its ability to classify objects. This network is expected to achieve an accuracy of approximately 40%.\n",
                "\n",
                "Additionally, you are required to save one of your best model checkpoints as mlp.pth in the current folder. This file will be used for automated testing.\n",
                "\n",
                "Furthermore, please implement a confusion matrix in the utils file, specifically within the val_step method of the Pipeline class. You may use any available implementation of the confusion matrix, but ensure that all tests continue to pass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c8da3018",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Epoch count:  0\n",
                        "0 3400.527218222618 31.11\n",
                        "Epoch count:  1\n",
                        "1 3331.1191008090973 33.53\n",
                        "Epoch count:  2\n",
                        "2 3291.7306874990463 35.54\n",
                        "Epoch count:  3\n",
                        "3 3262.4975513219833 35.89\n",
                        "Epoch count:  4\n",
                        "4 3239.354687809944 37.82\n",
                        "Epoch count:  5\n",
                        "5 3215.6702715158463 38.15\n",
                        "Epoch count:  6\n",
                        "6 3193.0151126384735 38.75\n",
                        "Epoch count:  7\n",
                        "7 3171.308514356613 40.08\n",
                        "Epoch count:  8\n",
                        "8 3152.6560536623 40.47\n",
                        "Epoch count:  9\n",
                        "9 3135.788097023964 40.87\n",
                        "Epoch count:  10\n",
                        "10 3120.009840607643 40.9\n",
                        "Epoch count:  11\n",
                        "11 3103.455713391304 41.66\n",
                        "Epoch count:  12\n",
                        "12 3088.241130232811 41.96\n",
                        "Epoch count:  13\n",
                        "13 3074.137999534607 42.11\n",
                        "Epoch count:  14\n",
                        "14 3060.692687392235 41.77\n",
                        "Epoch count:  15\n",
                        "15 3047.404439687729 41.78\n",
                        "Epoch count:  16\n",
                        "16 3034.24230158329 42.95\n",
                        "Epoch count:  17\n",
                        "17 3022.6364294290543 42.95\n",
                        "Epoch count:  18\n",
                        "18 3011.344106078148 43.14\n",
                        "Epoch count:  19\n",
                        "19 2998.8816796541214 43.48\n",
                        "Epoch count:  20\n",
                        "20 2988.665172457695 42.91\n",
                        "Epoch count:  21\n",
                        "21 2977.8426369428635 43.52\n",
                        "Epoch count:  22\n",
                        "22 2969.1602281332016 43.78\n",
                        "Epoch count:  23\n",
                        "23 2958.0885635614395 43.91\n",
                        "Epoch count:  24\n",
                        "24 2948.0079699754715 43.21\n",
                        "Epoch count:  25\n",
                        "25 2939.939925789833 43.76\n",
                        "Epoch count:  26\n",
                        "26 2930.863680958748 43.9\n",
                        "Epoch count:  27\n",
                        "27 2922.17514026165 44.07\n",
                        "Epoch count:  28\n",
                        "28 2914.250258207321 44.23\n",
                        "Epoch count:  29\n",
                        "29 2906.4635832309723 44.57\n",
                        "Epoch count:  30\n",
                        "30 2897.671815752983 43.96\n",
                        "Epoch count:  31\n",
                        "31 2890.756085395813 44.3\n",
                        "Epoch count:  32\n",
                        "32 2883.1155281066895 43.94\n",
                        "Epoch count:  33\n",
                        "33 2876.31456387043 43.81\n",
                        "Epoch count:  34\n",
                        "34 2868.9033926725388 44.71\n",
                        "Epoch count:  35\n",
                        "35 2864.2640134096146 44.58\n",
                        "Epoch count:  36\n",
                        "36 2856.328928232193 44.15\n",
                        "Epoch count:  37\n",
                        "37 2851.9137761592865 44.18\n",
                        "Epoch count:  38\n",
                        "38 2843.922627687454 44.17\n",
                        "Epoch count:  39\n",
                        "39 2840.791974902153 44.08\n"
                    ]
                }
            ],
            "source": [
                "# Lets train a CIFAR10 image classifier\n",
                "import importlib\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import networks as net\n",
                "import os\n",
                "importlib.reload(net)\n",
                "\n",
                "print(torch.cuda.is_available())\n",
                "pipeline = net.Pipeline()\n",
                "\n",
                "model = net.CustomMLP().to(pipeline.device)\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
                "\n",
                "home_path = os.path.expanduser(\"~\")\n",
                "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
                "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/mlp/\")\n",
                "\n",
                "import os\n",
                "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
                "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
                "\n",
                "epochs = 40\n",
                "trainLossList = []\n",
                "valAccList = []\n",
                "for eIndex in range(epochs):\n",
                "    print(\"Epoch count: \", eIndex)\n",
                "\n",
                "    train_epochloss = pipeline.train_step(model, optimizer)\n",
                "    val_acc = pipeline.val_step(model)\n",
                "\n",
                "    print(eIndex, train_epochloss, val_acc)\n",
                "\n",
                "    valAccList.append(val_acc)\n",
                "    trainLossList.append(train_epochloss)\n",
                "\n",
                "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
                "    torch.save(model.state_dict(), trainedMdlPath)\n",
                "\n",
                "trainLosses = np.array(trainLossList)\n",
                "testAccuracies = np.array(valAccList)\n",
                "\n",
                "np.savetxt(\"train.log\", trainLosses)\n",
                "np.savetxt(\"test.log\", testAccuracies)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e20b1e2d",
            "metadata": {},
            "source": [
                "### Part 3: Implement Convolutional Neural Networks (CNN) Using PyTorch layers"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d37c6b38",
            "metadata": {},
            "source": [
                "CNNs excel in capturing local patterns and spatial hierarchies through convolutional filters, which makes them more effective for image and spatial data. They also use parameter sharing, reducing the number of parameters and computational cost compared to MLPs. Additionally, CNNs offer translation invariance and hierarchical feature learning, enabling them to recognize features across different spatial locations and build complex patterns efficiently.\n",
                "\n",
                "Open networks.py and implement `RefCNN` using the inbuilt layers in pytorch. Make sure it is similar to CustomCNN() which uses custom layers.\n",
                "\n",
                "Train and compare the train loss and validation accuracy against MLP. \n",
                "\n",
                "Please copy the best checkpoint file in current folder as cnn_inbuilt.pth for automated tests. It is expected to be higher than 50%."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "3c9a9cad",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "optimizer got an empty parameter list",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mRefCNN()\u001b[38;5;241m.\u001b[39mto(pipeline\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m home_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m JOB_FOLDER\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(home_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:72\u001b[0m, in \u001b[0;36mAdamW.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     61\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     62\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[1;32m     71\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
                        "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:362\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    360\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    364\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n",
                        "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
                    ]
                }
            ],
            "source": [
                "# Lets train a CIFAR10 image classifier\n",
                "import importlib\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import networks as net\n",
                "import os\n",
                "importlib.reload(net)\n",
                "\n",
                "pipeline = net.Pipeline()\n",
                "model = net.RefCNN().to(pipeline.device)\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
                "\n",
                "home_path = os.path.expanduser(\"~\")\n",
                "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
                "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_inbuilt_layers/\")\n",
                "\n",
                "import os\n",
                "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
                "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
                "\n",
                "epochs = 40\n",
                "trainLossList = []\n",
                "valAccList = []\n",
                "for eIndex in range(epochs):\n",
                "    # print(\"Epoch count: \", eIndex)\n",
                "    \n",
                "    train_epochloss = pipeline.train_step(model, optimizer)\n",
                "    print(\"train complete\")\n",
                "    val_acc = pipeline.val_step(model)\n",
                "\n",
                "    print(eIndex, train_epochloss, val_acc)\n",
                "\n",
                "    valAccList.append(val_acc)\n",
                "    trainLossList.append(train_epochloss)\n",
                "\n",
                "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
                "    torch.save(model.state_dict(), trainedMdlPath)\n",
                "\n",
                "trainLosses = np.array(trainLossList)\n",
                "testAccuracies = np.array(valAccList)\n",
                "\n",
                "np.savetxt(\"train.log\", trainLosses)\n",
                "np.savetxt(\"test.log\", testAccuracies)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee9b9224",
            "metadata": {},
            "source": [
                "### Part 4: Implement Your Custom Layers for Convolutional Neural Networks (CNN)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5e78b4fe",
            "metadata": {},
            "source": [
                "Open custom_layers.py and implement the CustomConvLayer.\n",
                "\n",
                "Verify it by running the below code. Feel free to modify the below snippet. But do not modify my test.py\n",
                "\n",
                "For more information about supplying gradients, please refer to [examples_autograd](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "id": "d23dc62f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conv. Inference\n",
                        "tensor([[[[ 2.8335,  0.7377],\n",
                        "          [ 1.7001,  1.1648]],\n",
                        "\n",
                        "         [[-7.7356, -2.4510],\n",
                        "          [-2.2436, -4.8565]],\n",
                        "\n",
                        "         [[-0.6871,  2.6981],\n",
                        "          [ 1.0443, -0.6890]]]], grad_fn=<ConvolutionBackward0>)\n",
                        "tensor([[[[ 2.8335,  0.7377],\n",
                        "          [ 1.7001,  1.1648]],\n",
                        "\n",
                        "         [[-7.7356, -2.4510],\n",
                        "          [-2.2436, -4.8565]],\n",
                        "\n",
                        "         [[-0.6871,  2.6981],\n",
                        "          [ 1.0443, -0.6890]]]], grad_fn=<CustomConvLayerBackward>)\n",
                        "torch.Size([1, 2, 5, 5]) 3 2\n",
                        "torch.Size([3, 2, 3, 3]) torch.Size([3, 2, 3, 3])\n",
                        "gradients of loss relative to the weights\n",
                        "tensor([[[[ 0.6583,  0.7288,  0.5923],\n",
                        "          [ 0.5948,  0.7034,  0.4230],\n",
                        "          [ 0.4190,  0.6695,  0.8657]],\n",
                        "\n",
                        "         [[ 0.2217,  0.3440,  0.5351],\n",
                        "          [ 0.6452,  0.8107,  0.9362],\n",
                        "          [ 0.1707,  0.7146,  0.4641]]],\n",
                        "\n",
                        "\n",
                        "        [[[-1.9882, -1.9193, -1.3819],\n",
                        "          [-1.6023, -1.9598, -1.0295],\n",
                        "          [-1.4018, -1.6512, -2.2770]],\n",
                        "\n",
                        "         [[-0.7714, -0.7671, -1.5449],\n",
                        "          [-1.8578, -2.3140, -2.4679],\n",
                        "          [-0.5060, -2.0789, -1.2687]]],\n",
                        "\n",
                        "\n",
                        "        [[[-0.0248,  0.3662,  0.4881],\n",
                        "          [ 0.2019, -0.0877,  0.0130],\n",
                        "          [ 0.3412,  0.1129,  0.1004]],\n",
                        "\n",
                        "         [[ 0.0345,  0.1280,  0.2018],\n",
                        "          [ 0.3909, -0.0228,  0.0042],\n",
                        "          [ 0.2550,  0.0706,  0.4034]]]])\n",
                        "tensor([[[[ 0.6583,  0.7288,  0.5923],\n",
                        "          [ 0.5948,  0.7034,  0.4230],\n",
                        "          [ 0.4190,  0.6695,  0.8657]],\n",
                        "\n",
                        "         [[ 0.2217,  0.3440,  0.5351],\n",
                        "          [ 0.6452,  0.8107,  0.9362],\n",
                        "          [ 0.1707,  0.7146,  0.4641]]],\n",
                        "\n",
                        "\n",
                        "        [[[-1.9882, -1.9193, -1.3819],\n",
                        "          [-1.6023, -1.9598, -1.0295],\n",
                        "          [-1.4018, -1.6512, -2.2770]],\n",
                        "\n",
                        "         [[-0.7714, -0.7671, -1.5449],\n",
                        "          [-1.8578, -2.3140, -2.4679],\n",
                        "          [-0.5060, -2.0789, -1.2687]]],\n",
                        "\n",
                        "\n",
                        "        [[[-0.0248,  0.3662,  0.4881],\n",
                        "          [ 0.2019, -0.0877,  0.0130],\n",
                        "          [ 0.3412,  0.1129,  0.1004]],\n",
                        "\n",
                        "         [[ 0.0345,  0.1280,  0.2018],\n",
                        "          [ 0.3909, -0.0228,  0.0042],\n",
                        "          [ 0.2550,  0.0706,  0.4034]]]])\n",
                        "gradients of loss relative to the bias\n",
                        "tensor([ 1.0727, -2.8811,  0.3944])\n",
                        "tensor([ 1.0727, -2.8811,  0.3944])\n",
                        "gradients of loss relative to the input\n",
                        "tensor([[[[ 2.6742, -0.2723,  1.9931,  1.2891,  0.7810],\n",
                        "          [-0.2692,  1.3591, -0.6859,  0.0139, -0.2647],\n",
                        "          [-0.5441,  0.9243,  2.8899, -0.8401, -0.6815],\n",
                        "          [-0.2587,  0.2618, -0.2155,  0.8600, -0.2796],\n",
                        "          [-0.9591, -0.0179, -1.0530,  0.1553,  1.2267]],\n",
                        "\n",
                        "         [[ 1.1494, -4.4324, -1.3457, -0.2682, -1.0595],\n",
                        "          [-1.7683,  2.3548,  0.6872,  0.3207,  0.4331],\n",
                        "          [ 1.3312,  1.3802,  1.2049, -2.4186, -1.1102],\n",
                        "          [-0.4457,  0.7111, -0.9784,  1.3769,  0.8099],\n",
                        "          [ 0.0600,  0.8599,  0.8992,  1.1446,  0.9666]]]])\n",
                        "tensor([[[[ 2.6742, -0.2723,  1.9931,  1.2891,  0.7810],\n",
                        "          [-0.2692,  1.3591, -0.6859,  0.0139, -0.2647],\n",
                        "          [-0.5441,  0.9243,  2.8899, -0.8401, -0.6815],\n",
                        "          [-0.2587,  0.2618, -0.2155,  0.8600, -0.2796],\n",
                        "          [-0.9591, -0.0179, -1.0530,  0.1553,  1.2267]],\n",
                        "\n",
                        "         [[ 1.1494, -4.4324, -1.3457, -0.2682, -1.0595],\n",
                        "          [-1.7683,  2.3548,  0.6872,  0.3207,  0.4331],\n",
                        "          [ 1.3312,  1.3802,  1.2049, -2.4186, -1.1102],\n",
                        "          [-0.4457,  0.7111, -0.9784,  1.3769,  0.8099],\n",
                        "          [ 0.0600,  0.8599,  0.8992,  1.1446,  0.9666]]]])\n"
                    ]
                }
            ],
            "source": [
                "import importlib\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import networks as net\n",
                "import os\n",
                "importlib.reload(net)\n",
                "\n",
                "inbuiltLayer = nn.Conv2d(2, 3, 3, stride=2, padding='valid')\n",
                "customLayer = net.CustomConv2d(2, 3, 3, 2)\n",
                "\n",
                "inbuiltLayer.weight.data.copy_(customLayer.weight.data)\n",
                "inbuiltLayer.bias.data.copy_(customLayer.bias.data)\n",
                "\n",
                "u1 = torch.rand((1, 2, 5, 5), requires_grad=True)\n",
                "u2 = u1.detach().clone()\n",
                "u2.requires_grad_()\n",
                "\n",
                "y1 = inbuiltLayer(u1)\n",
                "y2 = customLayer(u2)\n",
                "\n",
                "print(\"Conv. Inference\")\n",
                "print(y1)\n",
                "print(y2)\n",
                "\n",
                "lossFunc = nn.MSELoss()\n",
                "loss_custom = lossFunc(y2, torch.zeros_like(y2))\n",
                "loss_in = lossFunc(y1, torch.zeros_like(y1))\n",
                "\n",
                "loss_in.backward()\n",
                "loss_custom.backward()\n",
                "\n",
                "print(\"gradients of loss relative to the weights\")\n",
                "print(inbuiltLayer.weight.grad)\n",
                "print(customLayer.weight.grad)\n",
                "# print(inbuiltLayer.weight.grad / customLayer.weight.grad)\n",
                "\n",
                "print(\"gradients of loss relative to the bias\")\n",
                "print(inbuiltLayer.bias.grad)\n",
                "print(customLayer.bias.grad)\n",
                "\n",
                "print(\"gradients of loss relative to the input\")\n",
                "print(u1.grad)\n",
                "print(u2.grad)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cf028b78",
            "metadata": {},
            "source": [
                "### Part 5: CNN Network Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f5ca731",
            "metadata": {},
            "source": [
                "Train and compare the train loss and validation accuracy against MLP and inbuilt conv layers. \n",
                "\n",
                "Please copy the best checkpoint file in current folder as `cnn_custom.pth` for automated tests. It is expected to be higher than 50%."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a8f31b30",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lets train a CIFAR10 image classifier\n",
                "import importlib\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import networks as net\n",
                "import os\n",
                "importlib.reload(net)\n",
                "\n",
                "pipeline = net.Pipeline()\n",
                "model = net.CustomCNN().to(pipeline.device)\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
                "\n",
                "home_path = os.path.expanduser(\"~\")\n",
                "JOB_FOLDER=os.path.join(home_path, \"outputs/\")\n",
                "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_custom_layer/\")\n",
                "\n",
                "import os\n",
                "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
                "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
                "\n",
                "epochs = 40\n",
                "trainLossList = []\n",
                "valAccList = []\n",
                "for eIndex in range(epochs):\n",
                "    # print(\"Epoch count: \", eIndex)\n",
                "    \n",
                "    train_epochloss = pipeline.train_step(model, optimizer)\n",
                "    print(\"train complete\")\n",
                "    val_acc = pipeline.val_step(model)\n",
                "\n",
                "    print(eIndex, train_epochloss, val_acc)\n",
                "\n",
                "    valAccList.append(val_acc)\n",
                "    trainLossList.append(train_epochloss)\n",
                "\n",
                "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
                "    torch.save(model.state_dict(), trainedMdlPath)\n",
                "\n",
                "trainLosses = np.array(trainLossList)\n",
                "testAccuracies = np.array(valAccList)\n",
                "\n",
                "np.savetxt(\"train.log\", trainLosses)\n",
                "np.savetxt(\"test.log\", testAccuracies)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "54272187",
            "metadata": {},
            "source": [
                "## 5. Grading Rubric\n",
                "\n",
                "- part 1 : 60\n",
                "- part 2 : 10\n",
                "- part 3 : 10\n",
                "- part 4 : 10\n",
                "- part 5 : 10\n",
                "\n",
                "For RBE474X: part1 + part2 + part3 = 100% of the grade (80/80).\n",
                "For RBE595-A01-SP: You are expected to implement part1-part5 for getting full credits (100/100).\n",
                "\n",
                "Your code will be evaluated with test.py. Please run it and ensure that the tests pass before submitting. Instructions are in software setup section.\n",
                "\n",
                "Please note that I will replace the test.py with my original test.py before evaluating.\n",
                "\n",
                "Please do not submit the data folder that is downloaded while training the network. It is over 300 MB. Anyone submitting data will be penalized! Your submission should not be more than 20 MB.\n",
                "\n",
                "## 6. Report Guidelines\n",
                "\n",
                "Report must be in Latex.\n",
                "\n",
                "Include the following,\n",
                "\n",
                "1. Training loss curve (loss vs epoch count)\n",
                "2. Confusion Matrix for validation set (val_step)\n",
                "3. Accuracy comparison between MLP, CNN (torch layers) and CNN (custom_layers)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
